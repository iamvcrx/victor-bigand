<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="keywords" content="">
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
	<meta name="robots" content="index, follow">
    <link rel="shortcut icon" type="image/png" href="../favicon.png">
    
	<link rel="stylesheet" type="text/css" href="../css/bootstrap.min.css?3109">
	<link rel="stylesheet" type="text/css" href="../style.css?2989">
	<link rel="stylesheet" type="text/css" href="../css/ionicons.min.css">
	<link rel="stylesheet" type="text/css" href="../css/all.min.css">
	
    <title>odyssee-du-cerveau</title>

<style>
.video235::before {padding-top: 33.02090844%!important}
</style>
    
<!-- Analytics -->
 
<!-- Analytics END -->
    
</head>
<body data-clean-url="true">

<!-- Preloader -->
<div id="page-loading-blocs-notifaction" class="page-preloader"></div>
<!-- Preloader END -->


<!-- Main container -->
<div class="page-container">
    
<!-- bloc-0 -->
<div class="bloc l-bloc " id="bloc-0">
	<div class="container bloc-no-padding-md bloc-no-padding-sm bloc-no-padding bloc-sm-lg">
		<div class="row">
			<div class="col-sm-10 offset-sm-1 col-md-8 offset-md-2 col-lg-6 offset-lg-3 text-start">
				<div class="ratio mb-lg-0 ms-lg-0 me-lg-0 ratio-16x9 video235 mt-lg-5 mt-md-5 mt-sm-5 mt-5">
					<video controls="" class="embed-responsive-item" autoplay="autoplay" muted="muted" loop="loop" playsinline="playsinline">
						<source src="../vid/CleanShot%202024-05-29%20at%2014.08.44.mp4" type="video/mp4">Your browser does not support HTML5 video.
					</video>
				</div>
				<p class="lege mb-lg-5 mt-lg-1 mt-md-1 mb-md-5 mb-sm-5 mt-sm-1 mt-1 mb-4">
					Spectrogram displaying the sound of my name : Victor BIGAND.
				</p>
			</div>
		</div>
	</div>
</div>
<!-- bloc-0 END -->

<!-- bloc-1 -->
<div class="bloc l-bloc menu-geo none" id="bloc-1">
	<div class="container bloc-no-padding-lg bloc-no-padding-md bloc-no-padding-sm bloc-no-padding">
		<div class="row">
			<div class="col-md-4 text-start">
				<h1 class="menu-text h1-about-style mb-lg-0 mb-md-0 mb-sm-3 mb-3">
					<a class="menu-text menu-geo" href="../">ABOUT ME</a>
				</h1>
			</div>
			<div class="col-md-4 text-start menu-text">
				<h1 class="menu-text mb-lg-0 mb-md-0 mb-sm-0 mb-0">
					<a class="menu-text" href="../music-page/">MUSIC/ART</a>
				</h1>
			</div>
			<div class="col-md-4 col">
				<h1 class="menu-text mb-lg-0 mb-md-0 mb-sm-3 mb-3">
					<a class="menu-text" href="../engineering-page/">ENGINEERING</a>
				</h1>
			</div>
		</div>
		<div class="row">
			<div class="col">
				<div class="divider-h mb-lg-3 mt-lg-3 divider-style mb-md-3 mt-md-3 mt-sm-3 mb-sm-3 mt-3 mb-3">
				</div>
			</div>
		</div>
	</div>
</div>
<!-- bloc-1 END -->

<!-- bloc-12 -->
<div class="bloc l-bloc content-bloc-margin" id="bloc-12">
	<div class="container bloc-no-padding-lg bloc-no-padding">
		<div class="row">
			<div class="text-start offset-lg-0 col-lg-12 col-sm-12 offset-sm-0 col-12 col-md-12 offset-md-0">
				<h6 class="mt-lg-5 h1-style-1 mb-lg-5 mt-4 mb-5">
					L’odyssée du cerveau - my work
				</h6>
				<h6 class="mb-lg-3 h1-style-2 h6-32-style mb-3">
					Project ambitions
				</h6>
				<p class="paragraph-text">
					This theater show mixes art and sicence to explain how our brains work while listening to music. This particular form is intended for non scientific people so the show needs to be ludic and visually meaningful as scientific oral explanations could lose the audience.<br><br>In that context, visual interactions and lighting animations of the brain are put at the front of the stage and needs to be as realistic as simple to understand.<br><br>As a string quartet plays music live to directly stimulate our brains during the show, the choice of real-time light generation reacting to music was made.<br><br>The principal questions arising from this context are : <br>
				</p>
				<ul class="icon-lists">
					<li>
						<p class="paragraph-text">
							how the brain structures responds to music (following neurosciences research) ?
						</p>
					</li>
				</ul>
				<ul class="icon-lists">
					<li>
						<p class="paragraph-text">
							how can we retrieve pertinent informations in the audio signal ?
						</p>
					</li>
				</ul>
				<ul class="icon-lists">
					<li>
						<p class="paragraph-text mb-lg-5 mb-5">
							how can we use those informations to generate light that will simply express the work of each brain structure ?
						</p>
					</li>
				</ul>
				<h6 class="mb-lg-3 h1-style-2 h6-33-style mb-3">
					Structure behaviors according to neurosciences
				</h6>
				<p class="paragraph-text mb-lg-5 mb-5">
					When we listen to music, the first structure receiving the information is <i>the basilar membrane</i>. It &nbsp;decomposes the sound in frequencies as a Fourier transform do.<br><br>Then, the information is treated by <i>the brain stem</i>. This structure listens to every details of the sound and start integrating informations like «&nbsp;the sound is wide&nbsp;» or « the sound is low&nbsp;».<br><br><i>The auditoral cortex</i> then starts analysing the tones and rythms in the signal. The left audio cortex detects onsets in the music while the right one analyses it tonality and notes organisation.<br><br><i>The arcuate fasciculuses</i> transmit those informations to <i>the frontal cortex</i> which analyses logical relationships between musical pieces with smart games stimulation : is this piece written by Mozart or by a more modern compositor like Gershwin ?<br><br><i>The motor cortex</i> analyses rhythm structures : it detects the beat, the tempo and enables human to anticipate music, synchronise and dance together.<br><br><i>The limbic system</i> is the one generating emotional responses from music listening.<br><br>Finally, <i>the hippocampus</i> is responsible for your musical memory often related to emotions like nostalgia.
				</p>
				<h6 class="h2-style mb-lg-3 h6-34-style mb-3">
					Real-time audio processing
				</h6>
				<p class="paragraph-text mb-lg-5 mb-5">
					The real time audio analysis algorithms are made in <i>Max MSP</i> software. By « real-time » we achieve 2.9ms of global latency (while some algorithms needs more buffer lengths to work well).<br><br>For <i>the basilar membrane</i>, a simple real-time Fourier transform is performed.<br><br>For <i>the brain stem</i>, we compute the RMS envelope, the spectral centroïd and spectral bandwidth of the sound of the quartet.<br><br>For <i>the left auditoral cortex</i>, real-time beat detection algorithms led to bad results as the string quartet audio signal has poor transients and onsets content. We finally chose to adjust tempo manually by tapping it.<br>For <i>the right auditoral cortex</i>, the tonality algorithm is based on P. Toiviainen’s article « <a class="paragraph-text link-style" href="../downloads/toiviainen2003.pdf" target="_blank">Measuring and modeling real-time responses to music: The dynamics of tonality induction</a> ». First, we compute « real-time » (93ms buffer length) chroma profile. Then, we compare it to each 24 chroma profiles of the 12 Major and minor tonalities by computing a correlation vector. We then added tonality induction effect by implementing a memory process (see article for further details).<br><br><i>The arcuate fasciculuses</i> only need to receive a mean RMS envelope of the sound.<br><br><i>The motor cortex</i> receives the tempo tapped manually.<br><br><i>Limbic system</i> only works on manual operations (no algorithms) so as the hippocampus.<br>
				</p>
				<h6 class="h2-style mb-lg-3 h6-35-style mb-3">
					Real-time visual generation examples
				</h6>
				<p class="paragraph-text mb-lg-4">
					For visual generation, we use <i>TouchDesigner</i> software linked with <i>Max MSP</i> following the OSC protocol. We are generating 30 frames per second and sending it to 3600 adressable LEDs following ArtNet and DMX protocols.<br>
				</p>
				<p class="paragraph-text p-20-style">
					Basilar membrane
				</p>
				<div class="ratio ratio-16x9 videos-margin">
					<video controls="" class="embed-responsive-item lazyload" data-src="../vid/falaise_spectro.mp4">
						
					</video>
				</div>
				<h6 class="mb-4 text-lg-end h6-bloc-12-style mb-lg-2 mt-lg-0">
					<i>Falaise - Floating Points</i>
				</h6>
				<p class="paragraph-text mb-lg-4">
					Here you can see a real-time spectrogram displaying frequencies along vertical axis and time along horizontal axis. This representation can describes the sort of information <i>the basilar membrane</i> receives when we hear things. This is also the representation used to make the top video of this website, writing my name using sound.
				</p>
				<p class="paragraph-text p-bloc-12-style">
					Brain stem
				</p>
				<div class="ratio ratio-16x9 videos-margin">
					<video controls="" class="embed-responsive-item lazyload" data-src="../vid/CleanShot%202024-05-31%20at%2015.25.00.mp4">
						
					</video>
				</div>
				<h6 class="mb-4 text-lg-end h6-bloc-12-style mb-lg-2 mt-lg-0">
					<i>String quartet in Fm, Hob. III:35, Op. 20 No.5 : 1. Moderato - J. Haydn by Emerson Quartet</i>
				</h6>
				<p class="paragraph-text mb-lg-4">
					In this video, you can see the precise RMS envelope of the sound for <i>the brain stem</i> (« TC&nbsp;» ) and the averaged one for <i>arcuate fasciculuses</i> (« FA&nbsp;»). You can also observe the variation of spectral centroïd and spectral spread along the audio. All of this generate the visual at the right. This image is 300 pixels wide as their is 300 LED pixels in the LED strip representing the brain stem.<br>You can observe the movement of a sort of white «&nbsp;snake&nbsp;». As the sound is getting lower in frequency, the snake moves to the left, which lights the bottom of the LED strip in real life. As the spectral spread increase, the snake is getting wider. Finally, the global intensity of the LED strip follows the «&nbsp;TC&nbsp;» RMS envelope.<br>
				</p>
				<p class="paragraph-text p-style">
					Right auditoral cortex
				</p>
				<div class="ratio ratio-16x9 videos-margin">
					<video controls="" class="embed-responsive-item lazyload" data-src="../vid/tonalite_beachhouse.mp4">
						
					</video>
				</div>
				<h6 class="mb-4 text-lg-end h6-bloc-12-style mb-lg-2 mt-lg-2">
					<i>On the Sea - Beach House</i>
				</h6>
				<p class="paragraph-text mb-lg-4">
					In this video, you can see the real-time 2D colormap result showing the tonality structure of the song «&nbsp;On the sea&nbsp;» by Beach House. You can track the progression of G, B, F and C chords with 93ms latency. This 2D map is generated in real-time on the brain during the show on a 42x24 LED &nbsp;pixel matrix.<br><br>Note : the key organisation of the map is not exactly as in the article but try to approximate it using a 3x24 matrix.<br>
				</p>
				<p class="paragraph-text p-26-style">
					Arcuate fasciculuses
				</p>
				<div class="ratio ratio-16x9 videos-margin">
					<video controls="" class="embed-responsive-item lazyload" data-src="../vid/fas_environment.mp4">
						
					</video>
				</div>
				<h6 class="mb-4 text-lg-end h6-bloc-12-style mb-lg-2 mt-lg-0">
					<i>Movement 1 - Floating Points, Pharaoh Sanders, London Symphony Orchestra</i>
				</h6>
				<p class="paragraph-text">
					In this video, you can see an example of how the <i>arcuate fasciculuses</i> behavior is interpreted. There is two little «&nbsp;snakes&nbsp;» illustrating nervous influx transporting information. Those influx are influenced by sound : as it gets louder, they move quicker and are more saturate, evoking the richness of the information they transport.<br><br><br>Finally, the other brain structures (<i>limbic system</i>, <i>motor cortex</i>, <i>left auditoral cortex</i> and <i>hippocampus</i>) are driven by manual operations for the moment so I will not present them here. Though, we are still improving the algorithms and hope we will find some automations, in the hope that this brain representation eventually become fully autonomous in the future.
				</p>
			</div>
		</div>
	</div>
</div>
<!-- bloc-12 END -->

<!-- ScrollToTop Button -->
<button aria-label="Scroll to top button" class="bloc-button btn btn-d scrollToTop" onclick="scrollToTarget('1',this)"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 32 32"><path class="scroll-to-top-btn-icon" d="M30,22.656l-14-13-14,13"/></svg></button>
<!-- ScrollToTop Button END-->


<!-- bloc-13 -->
<div class="bloc l-bloc" id="bloc-13">
	<div class="container bloc-no-padding-lg bloc-sm">
		<div class="row social-margin mt-lg-4 mb-lg-3 row-style">
			<div class="col-md-2 offset-md-3 col-sm-4 col-4">
				<div class="text-center">
					<a href="mailto:victorbigand@gmail.com"><span class="icon-sm ion ion-android-mail"></span></a>
				</div>
			</div>
			<div class="col-md-2 col-sm-4 col-4">
				<div class="text-center">
					<a href="https://songwhip.com/vcrx" target="_blank"><span class="icon-sm ion ion-music-note"></span></a>
				</div>
			</div>
			<div class="col-md-2 col-sm-4 col-3">
				<div class="text-center">
					<a href="https://www.instagram.com/iamvcrx/" target="_blank"><span class="fab fa-instagram icon-sm"></span></a>
				</div>
			</div>
		</div>
	</div>
</div>
<!-- bloc-13 END -->

<!-- bloc-9 -->
<div class="bloc l-bloc" id="bloc-9">
	<div class="container bloc-no-padding-lg bloc-no-padding-sm bloc-no-padding">
		<div class="row">
			<div class="col text-sm-center text-center">
				<h6 class="mb-4 text-lg-center h6-style mb-lg-5 pb-lg-5">
					all work copyright © Victor Bigand 2024 • all rights reserved
				</h6>
			</div>
		</div>
	</div>
</div>
<!-- bloc-9 END -->

</div>
<!-- Main container END -->
    


<!-- Additional JS -->
<script src="../js/bootstrap.bundle.min.js?48"></script>
<script src="../js/blocs.min.js?1077"></script>
<script src="../js/lazysizes.min.js" defer></script><!-- Additional JS END -->


</body>
</html>
